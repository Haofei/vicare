@node lexical-tokens
@section Describing lexical tokens


@cindex @library{nausicaa parser-tools lexical-tokens}, library
@cindex Library @library{nausicaa parser-tools lexical-tokens}


It is an accepted pattern to split the interpretation of a stream of
text into a lexing step and a parsing step.  In such scenario a lexer
function fragments the input into @dfn{tokens} each of which is assigned
a @dfn{category}, the parser associates a semantic meaning to a sequence
of token categories.

The library @library{nausicaa parser-tools lexical-tokens} defines the
classes @class{lexical-token} and @class{source-location} which are
meant to be used by all the lexers and parsers distributed with
@value{PACKAGE}.

@menu
* lexical-tokens token::          Lexical token records.
* lexical-tokens silex::          SILex default semantic actions.
@end menu

@c page
@node lexical-tokens token
@subsection Lexical token records


@menu
* lexical-tokens token intro::  Overview of lexical tokens.
* lexical-tokens token token::  Lexical token class.
* lexical-tokens token error::  Lexical error class.
@end menu

@c page
@node lexical-tokens token intro
@subsubsection Overview of lexical tokens


Lexical token records are meant to store informations about a token from
the input stream; they should be produced by the lexer and consumed by
the parser.  For example, when the lexer tokenises the number @math{123}
from the string @samp{123}, it can build a record with:

@example
(let ((position ---))
  (make* <lexical-token> 'NUMBER position 123 3))
@end example

@noindent
while when tokenising a string it can do:

@example
(let ((position ---))
  (make* <lexical-token> 'STRING position "some text" 9))
@end example

When the lexer has to signal the end--of--input, it must return a token
with category @samp{*eoi*}, and continue to return it if it is called
again and again; it can do:

@example
(let ((position ---))
  (make* <lexical-token> '*eoi* position (eof-object)))
@end example

When the lexer closure has to signal a lexer error (an invalid character
from the input stream), it must return a token with category
@samp{*lexer-error*}.

@c page
@node lexical-tokens token token
@subsubsection Lexical token class


The following bindings are exported by the @library{nausicaa
parser-tools lexical-tokens} library; this library is built on top of
@library{nausicaa language classes}.


@deftp Class @aclass{lexical-token}
Hold the informations about a token from the input stream.
@end deftp


@defcv {Immutable Field} @aclass{lexical-token} category
Represents the grammar's terminal symbol to which this token belongs.
Every parser @api{} must provide an interface to specify the list of
allowed terminal symbols.
@end defcv


@defcv {Immutable Field} @aclass{lexical-token} location
Represents the location in the input from which the token was built; it
must be @false{} or an instance of @class{source-location} record.
@end defcv


@defcv {Immutable Field} @aclass{lexical-token} value
Represents the semantic value associated with the token.  It can be any
Scheme value.
@end defcv


@defcv {Immutable Field} @aclass{lexical-token} length
It is meant to be the length of the string which generated the token.
When the token represents the end--of--input, this field can be set to
zero.
@end defcv


@defcv {Immutable Virtual Field} @aclass{lexical-token} end-of-input?
True if the token has category @samp{*eoi*}.
@end defcv


@defcv {Immutable Virtual Field} @aclass{lexical-token} lexer-error?
True if the token has category @samp{*lexer-error*}.
@end defcv


@defcv {Immutable Virtual Field} @aclass{lexical-token} special?
True if the token has category @samp{*eoi*} or @samp{*lexer-error*}.
@end defcv


@defop Syntax @aclass{lexical-token} make* @aclass{lexical-token} @var{category} @var{location} @var{value} @var{length}
Build and return a new record of type @class{lexical-token}.
@end defop


@defop Syntax @aclass{lexical-token} make @aclass{lexical-token} @var{clause} ...
@defopx {Auxiliary Syntax} @aclass{lexical-token} category: @var{category}
@defopx {Auxiliary Syntax} @aclass{lexical-token} location: @var{location}
@defopx {Auxiliary Syntax} @aclass{lexical-token} value: @var{value}
@defopx {Auxiliary Syntax} @aclass{lexical-token} length: @var{length}
Build and return a new record of type @class{lexical-token}.  The
@func{category:} clause is mandatory; @var{location} defaults to
@false{}; @var{value} defaults to @false{}; @var{length} defaults to
zero.
@end defop


@defop Syntax @aclass{lexical-token} is-a? @var{obj} @aclass{lexical-token}
Return @true{} if @var{obj} is an instance of @class{lexical-token}.
@end defop

@c ------------------------------------------------------------

@subsubheading Traditional records @api{}


@defun make-<lexical-token> @var{category} @var{location} @var{value} @var{length}
Build and return a new record of type @class{lexical-token}.
@end defun


@defun make-<lexical-token>/end-of-input @var{location}
Build and return a new record of type @class{lexical-token} meant to
represent the end--of--input.  The field @samp{category} is set to the
symbol @samp{*eoi*}, the field @samp{value} is set to
@samp{(eof-object)}, the field @samp{length} is set to zero.  The field
@samp{location} is set to @var{location}, which must be a
@class{source-location} record or @false{}.
@end defun


@defun make-<lexical-token>/lexer-error @var{location} @var{value} @var{length}
Build and return a new record of type @class{lexical-token} meant to
represent a lexer error.  The field @samp{category} is set to
@samp{*lexer-error*}, all the other fields are initialised with the
arguments.
@end defun


@defun <lexical-token>? @var{obj}
Return true if @var{obj} is a record of type of @class{lexical-token}.
@end defun


@defun <lexical-token>?/end-of-input @var{obj}
Return true if @var{obj} is an instance of @class{lexical-token} having
category @func{eq?} to the symbol @samp{*eoi*}.
@end defun


@defun <lexical-token>?/lexer-error @var{obj}
Return true if @var{obj} is an instance of @class{lexical-token} having
category @func{eq?} to the symbol @samp{*lexer-error*}.
@end defun


@defun <lexical-token>?/special @var{obj}
Return true if @var{obj} is an instance of @class{lexical-token} having
category @func{eq?} to the symbol @samp{*eoi*} or @samp{*lexer-error*}.
@end defun


@defun <lexical-token>-category @var{tok}
@defunx <lexical-token>-location @var{tok}
@defunx <lexical-token>-value @var{tok}
@defunx <lexical-token>-length @var{tok}
Accessors for the fields of @class{lexical-token} records.
@end defun

@c page
@node lexical-tokens token error
@subsubsection Lexical error class


The following bindings are exported by the @library{nausicaa
parser-tools lexical-tokens} library; this library is built on top of
@library{nausicaa language classes}.


@deftp Class @aclass{lexer-error}
Hold the informations about a lexer error; it is derived from
@class{lexical-token}.  The value of the @code{category} field is always
@samp{*lexer-error*}.
@end deftp


@defcv {Immutable Field} @aclass{lexer-error} message
A Scheme string describing the error.
@end defcv


@defop Syntax @aclass{lexer-error} make* @aclass{lexer-error} @var{location} @var{value} @var{length} @var{message}
Build and return a new record of type @class{lexer-error}.
@end defop


@defop Syntax @aclass{lexer-error} make @aclass{lexer-error} @var{clause} ...
@defopx {Auxiliary Syntax} @aclass{lexer-error} location: @var{location}
@defopx {Auxiliary Syntax} @aclass{lexer-error} value: @var{value}
@defopx {Auxiliary Syntax} @aclass{lexer-error} length: @var{length}
@defopx {Auxiliary Syntax} @aclass{lexer-error} error-message: @var{message}
Build and return a new record of type @class{lexer-error}.  The
@func{error-message:} clause is mandatory; @var{location} defaults to
@false{}; @var{value} defaults to @false{}; @var{length} defaults to
zero.
@end defop


@defop Syntax @aclass{lexer-error} is-a? @var{obj} @aclass{lexer-error}
Return @true{} if @var{obj} is an instance of @class{lexer-error}.
@end defop

@c ------------------------------------------------------------

@subsubheading Traditional records @api{}


@defun make-<lexer-error> @var{location} @var{value} @var{length} @var{message}
Build and return a new record of type @class{lexer-error}.
@end defun


@defun <lexer-error>? @var{obj}
Return true if @var{obj} is a record of type of @class{lexer-error}.
@end defun


@defun <lexer-error>-message @var{tok}
Accessor for the field of @class{lexer-error} records.
@end defun

@c page
@node lexical-tokens silex
@subsection SILex default semantic actions


@cindex @library{nausicaa parser-tools silex default-error-handler}, library
@cindex Library @library{nausicaa parser-tools silex default-error-handler}


The following bindings are exported by the @library{nausicaa
parser-tools silex default-error-handler} library.  The library is meant
to be included in generated SILex table libraries using the
@func{library-imports:} clause of @func{lex}, @vicareref{silex, A
lexical analyser generator}.


@deffn Syntax silex-default-error-handler
@deffnx Syntax silex-default-error-handler @meta{yytext}
Expand to a custom semantic action for the @samp{<<ERROR>>} rule; it is
meant to be used in SILex table files as:

@example
<<ERROR>>       (silex-default-error-handler)
@end example

The semantic action builds and returns a record of type
@class{lexical-token} with category @samp{*lexer-error*} and semantic
value set to an error string describing the input that caused the error;
the default @code{yytext} binding is used to build the error string.

When the optional @meta{yytex} argument is present: this value is used
in place of @code{yytext} to build the error message string.
@end deffn


@deffn Syntax silex-default-eof-handler
Expand to a custom semantic action for the @samp{<<EOF>>} rule; it is
meant to be used in SILex table files as:

@example
<<EOF>>         (silex-default-eof-handler)
@end example

The semantic action builds and returns a record of type
@class{lexical-token} with category @samp{*eoi*}, semantic value set to
@code{(eof-object)} and length set to zero.
@end deffn


@c end of file
